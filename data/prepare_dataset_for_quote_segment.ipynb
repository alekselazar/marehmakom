{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51a720e",
   "metadata": {},
   "source": [
    "I created MarkedUpTextChunks quotes for all Rashi on Tanakh\n",
    "So now I want to create a dataset for labse-cnn quotes segmentation model\n",
    "Also, to train the model to recognize \"Yeshibish\" language, I composed syntetic dataset from Talmud and Tosafot texts in hebrew and english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b8a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = Tokenizer.from_file('labse_tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "397713da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tuples.pkl\", \"rb\") as f:\n",
    "    raw_sents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_span(ids: List[int], min_len=3, max_len=12) -> Tuple[int,int]:\n",
    "    if not ids:\n",
    "        return 0, 0\n",
    "    if len(ids) <= min_len:\n",
    "        return 0, len(ids)\n",
    "    L = random.randint(min_len, min(max_len, len(ids)))\n",
    "    s = random.randint(0, len(ids) - L)\n",
    "    return s, s + L\n",
    "\n",
    "def gather_background_ids(raw_sent: List[List[str]], min_tokens: int) -> List[int]:\n",
    "    \"\"\"Concatenate random sentence variants until tokenized length >= min_tokens.\"\"\"\n",
    "    acc: List[str] = []\n",
    "    ids: List[int] = []\n",
    "    while len(ids) < min_tokens:\n",
    "        group   = random.choice(raw_sent)      # pick a parallel sentence set\n",
    "        variant = random.choice(group) or \"\"   # any language variant allowed\n",
    "        if not variant.strip():\n",
    "            continue\n",
    "        acc.append(variant.strip())\n",
    "        ids = TOKENIZER.encode(\" \".join(acc), add_special_tokens=False).ids\n",
    "    return ids\n",
    "\n",
    "def insert_tokens(bg_ids: List[int], span_ids: List[int]) -> Tuple[List[int], int]:\n",
    "    if not bg_ids:\n",
    "        return span_ids.copy(), 0\n",
    "    pos = random.randint(0, len(bg_ids))\n",
    "    out = bg_ids[:pos] + span_ids + bg_ids[pos:]\n",
    "    return out, pos\n",
    "\n",
    "def make_dataset_from_raw_sent(\n",
    "    raw_sent: List[List[str]],\n",
    "    n_samples: int = 20000,\n",
    "    max_query_len: int = 128,\n",
    "    max_target_len: int = 480,\n",
    "    ensure_bg_tokens: int = 200,\n",
    "    neg_ratio: float = 0.2,\n",
    "    seed: int = 42,\n",
    "    per_query_multiplier: int = 1,     \n",
    "    targets_hebrew_only: bool = False\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Build synthetic (query, target, mask) triples:\n",
    "      - query = full sentence (any language) from raw_sent\n",
    "      - choose a random subspan of the query tokens\n",
    "      - build a random background (any language mix by default) and insert the span (unless negative)\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    if not raw_sent:\n",
    "        return out\n",
    "\n",
    "    for _ in tqdm(range(n_samples)):\n",
    "        group = random.choice(raw_sent)\n",
    "        if not group:\n",
    "            continue\n",
    "\n",
    "        # pick ANY language sentence as query\n",
    "        q_text = random.choice(group)\n",
    "        if not q_text or not q_text.strip():\n",
    "            continue\n",
    "\n",
    "        q_ids: List[int] = TOKENIZER.encode(q_text, add_special_tokens=False).ids[:max_query_len]\n",
    "        if not q_ids:\n",
    "            continue\n",
    "\n",
    "        for _rep in range(per_query_multiplier):\n",
    "            # background ids\n",
    "            if targets_hebrew_only:\n",
    "                # concatenate only Hebrew variants (index 0)\n",
    "                acc, ids = [], []\n",
    "                while len(ids) < max(ensure_bg_tokens, len(q_ids)*3):\n",
    "                    g = random.choice(raw_sent)\n",
    "                    he = (g[0] if g and len(g) > 0 else \"\").strip()\n",
    "                    if not he:\n",
    "                        continue\n",
    "                    acc.append(he)\n",
    "                    ids = TOKENIZER.encode(\" \".join(acc), add_special_tokens=False).ids\n",
    "                bg_ids = ids\n",
    "            else:\n",
    "                bg_ids = gather_background_ids(raw_sent, min_tokens=max(ensure_bg_tokens, len(q_ids)*3))\n",
    "\n",
    "            # quote span (from the query tokens)\n",
    "            s, e = sample_span(q_ids, min_len=3, max_len=12)\n",
    "            span_ids = q_ids[s:e] if e > s else q_ids[:min(6, len(q_ids))]\n",
    "\n",
    "            # negatives some of the time\n",
    "            is_negative = (random.random() < neg_ratio or not span_ids)\n",
    "\n",
    "            if is_negative:\n",
    "                tgt_ids = bg_ids[:max_target_len]\n",
    "                mask = [0] * len(tgt_ids)\n",
    "            else:\n",
    "                tgt_all, insert_pos = insert_tokens(bg_ids, span_ids)\n",
    "                if len(tgt_all) > max_target_len:\n",
    "                    tgt_ids = tgt_all[:max_target_len]\n",
    "                    span_len   = len(span_ids)\n",
    "                    mask_start = min(insert_pos, max_target_len)\n",
    "                    mask_end   = min(insert_pos + span_len, max_target_len)\n",
    "                else:\n",
    "                    tgt_ids = tgt_all\n",
    "                    mask_start = insert_pos\n",
    "                    mask_end   = insert_pos + len(span_ids)\n",
    "\n",
    "                mask = [0] * len(tgt_ids)\n",
    "                for i in range(mask_start, mask_end):\n",
    "                    if 0 <= i < len(mask):\n",
    "                        mask[i] = 1\n",
    "\n",
    "            out.append({\n",
    "                \"query_tokenized\": q_ids,\n",
    "                \"target_tokenized\": tgt_ids,\n",
    "                \"target_mask\": mask\n",
    "            })\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc3edc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50001/50001 [04:31<00:00, 184.15it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150000,\n",
       " {'query_tokenized': [18225,\n",
       "   39706,\n",
       "   2976,\n",
       "   189,\n",
       "   15096,\n",
       "   85687,\n",
       "   208251,\n",
       "   14978,\n",
       "   15127,\n",
       "   17115,\n",
       "   14999,\n",
       "   424228,\n",
       "   73038,\n",
       "   15121,\n",
       "   15179,\n",
       "   15384,\n",
       "   19097,\n",
       "   27467,\n",
       "   49504,\n",
       "   111527,\n",
       "   16652,\n",
       "   41781,\n",
       "   19559,\n",
       "   15384,\n",
       "   102383,\n",
       "   111527,\n",
       "   16652,\n",
       "   15424,\n",
       "   117,\n",
       "   15595,\n",
       "   16068,\n",
       "   252273,\n",
       "   16143,\n",
       "   16207,\n",
       "   15002,\n",
       "   179469,\n",
       "   119],\n",
       "  'target_tokenized': [17192,\n",
       "   14985,\n",
       "   133670,\n",
       "   14978,\n",
       "   117,\n",
       "   19576,\n",
       "   14986,\n",
       "   15100,\n",
       "   15179,\n",
       "   34908,\n",
       "   119,\n",
       "   15385,\n",
       "   118,\n",
       "   42574,\n",
       "   14986,\n",
       "   15121,\n",
       "   170,\n",
       "   158122,\n",
       "   188838,\n",
       "   22684,\n",
       "   15131,\n",
       "   170,\n",
       "   153027,\n",
       "   15595,\n",
       "   27067,\n",
       "   400431,\n",
       "   15221,\n",
       "   118,\n",
       "   230098,\n",
       "   15294,\n",
       "   391170,\n",
       "   355774,\n",
       "   15058,\n",
       "   17192,\n",
       "   456093,\n",
       "   117,\n",
       "   208772,\n",
       "   57459,\n",
       "   15002,\n",
       "   15713,\n",
       "   14999,\n",
       "   424228,\n",
       "   73038,\n",
       "   15121,\n",
       "   15179,\n",
       "   15384,\n",
       "   19097,\n",
       "   27467,\n",
       "   101700,\n",
       "   119,\n",
       "   17192,\n",
       "   15294,\n",
       "   16651,\n",
       "   15100,\n",
       "   400431,\n",
       "   14986,\n",
       "   15308,\n",
       "   14997,\n",
       "   14985,\n",
       "   189386,\n",
       "   14981,\n",
       "   16512,\n",
       "   34158,\n",
       "   16998,\n",
       "   119,\n",
       "   33066,\n",
       "   920,\n",
       "   40112,\n",
       "   18428,\n",
       "   31520,\n",
       "   35379,\n",
       "   240460,\n",
       "   20259,\n",
       "   915,\n",
       "   19459,\n",
       "   224888,\n",
       "   90444,\n",
       "   17495,\n",
       "   35379,\n",
       "   46908,\n",
       "   138868,\n",
       "   15578,\n",
       "   500340,\n",
       "   165542,\n",
       "   121610,\n",
       "   131200,\n",
       "   53431,\n",
       "   15655,\n",
       "   35379,\n",
       "   379816,\n",
       "   138868,\n",
       "   15578,\n",
       "   500340,\n",
       "   165542,\n",
       "   121610,\n",
       "   131200,\n",
       "   53431,\n",
       "   15655,\n",
       "   133670,\n",
       "   279406,\n",
       "   27176,\n",
       "   22738,\n",
       "   131,\n",
       "   17169,\n",
       "   16068,\n",
       "   377161,\n",
       "   14978,\n",
       "   179469,\n",
       "   19802,\n",
       "   159951,\n",
       "   15015,\n",
       "   14985,\n",
       "   43837,\n",
       "   15222,\n",
       "   15595,\n",
       "   14986,\n",
       "   170,\n",
       "   231021,\n",
       "   59205,\n",
       "   119,\n",
       "   17192,\n",
       "   14985,\n",
       "   133670,\n",
       "   14978,\n",
       "   19576,\n",
       "   131,\n",
       "   60247,\n",
       "   15015,\n",
       "   14985,\n",
       "   43837,\n",
       "   14999,\n",
       "   15015,\n",
       "   14985,\n",
       "   16706,\n",
       "   117,\n",
       "   16512,\n",
       "   65291,\n",
       "   17054,\n",
       "   159951,\n",
       "   119,\n",
       "   17169,\n",
       "   16068,\n",
       "   22954,\n",
       "   17054,\n",
       "   71433,\n",
       "   15187,\n",
       "   117,\n",
       "   14986,\n",
       "   17231,\n",
       "   69076,\n",
       "   14985,\n",
       "   164932,\n",
       "   21727,\n",
       "   117,\n",
       "   14981,\n",
       "   170,\n",
       "   24365,\n",
       "   250306,\n",
       "   117,\n",
       "   16266,\n",
       "   15479,\n",
       "   117,\n",
       "   15222,\n",
       "   55536,\n",
       "   117,\n",
       "   15002,\n",
       "   179469,\n",
       "   17192,\n",
       "   15595,\n",
       "   16068,\n",
       "   67689,\n",
       "   14978,\n",
       "   17054,\n",
       "   446687,\n",
       "   119,\n",
       "   17192,\n",
       "   15595,\n",
       "   16068,\n",
       "   155324,\n",
       "   14981,\n",
       "   18189,\n",
       "   14986,\n",
       "   67689,\n",
       "   17054,\n",
       "   446687,\n",
       "   22569,\n",
       "   15936,\n",
       "   20615,\n",
       "   20569,\n",
       "   47515,\n",
       "   16266,\n",
       "   46225,\n",
       "   22390,\n",
       "   117,\n",
       "   31742,\n",
       "   49763,\n",
       "   22143,\n",
       "   132678,\n",
       "   19467,\n",
       "   52980,\n",
       "   15625,\n",
       "   38017,\n",
       "   15683,\n",
       "   26886,\n",
       "   167739,\n",
       "   15577,\n",
       "   74941,\n",
       "   299533,\n",
       "   187981,\n",
       "   19920,\n",
       "   150955,\n",
       "   14989,\n",
       "   53264,\n",
       "   16543,\n",
       "   119,\n",
       "   15942,\n",
       "   15020,\n",
       "   15863,\n",
       "   15531,\n",
       "   373095,\n",
       "   16775,\n",
       "   15329,\n",
       "   152555,\n",
       "   85930,\n",
       "   14989,\n",
       "   117,\n",
       "   15006,\n",
       "   15683,\n",
       "   15032,\n",
       "   43979,\n",
       "   266648,\n",
       "   16934,\n",
       "   19961,\n",
       "   239276,\n",
       "   15187,\n",
       "   15630,\n",
       "   19736,\n",
       "   15455,\n",
       "   258904,\n",
       "   119,\n",
       "   15050],\n",
       "  'target_mask': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = make_dataset_from_raw_sent(\n",
    "    raw_sents,\n",
    "    n_samples=50001,\n",
    "    max_query_len=512,\n",
    "    max_target_len=512,\n",
    "    ensure_bg_tokens=200,\n",
    "    neg_ratio=0.3,\n",
    "    seed=123,\n",
    "    per_query_multiplier=3,\n",
    "    targets_hebrew_only=False\n",
    ")\n",
    "\n",
    "len(dataset), dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37cf6310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_tokenized': [138,\n",
       "  15160,\n",
       "  48350,\n",
       "  15202,\n",
       "  144806,\n",
       "  23797,\n",
       "  20800,\n",
       "  91999,\n",
       "  45741,\n",
       "  19143,\n",
       "  26567,\n",
       "  18491,\n",
       "  50962,\n",
       "  17728,\n",
       "  15897,\n",
       "  195,\n",
       "  99550,\n",
       "  155527,\n",
       "  283209,\n",
       "  19143,\n",
       "  434340,\n",
       "  15897,\n",
       "  15214,\n",
       "  50896,\n",
       "  170478,\n",
       "  14991,\n",
       "  15214,\n",
       "  99550,\n",
       "  27579,\n",
       "  16163,\n",
       "  178,\n",
       "  175593,\n",
       "  29381,\n",
       "  18902,\n",
       "  15214,\n",
       "  99550,\n",
       "  33920,\n",
       "  286186,\n",
       "  178,\n",
       "  21664,\n",
       "  245355,\n",
       "  379,\n",
       "  224346,\n",
       "  500744,\n",
       "  15105,\n",
       "  15214,\n",
       "  99550,\n",
       "  29661,\n",
       "  83016,\n",
       "  15160,\n",
       "  499627,\n",
       "  18588,\n",
       "  17728,\n",
       "  170,\n",
       "  14977,\n",
       "  29661,\n",
       "  183476,\n",
       "  85433,\n",
       "  15160,\n",
       "  159281,\n",
       "  171717,\n",
       "  352365],\n",
       " 'target_tokenized': [919,\n",
       "  211283,\n",
       "  48637,\n",
       "  31993,\n",
       "  16153,\n",
       "  926,\n",
       "  116109,\n",
       "  18721,\n",
       "  48824,\n",
       "  78521,\n",
       "  15578,\n",
       "  919,\n",
       "  85778,\n",
       "  43015,\n",
       "  923,\n",
       "  382504,\n",
       "  85845,\n",
       "  23552,\n",
       "  27972,\n",
       "  459698,\n",
       "  211283,\n",
       "  15578,\n",
       "  24737,\n",
       "  18240,\n",
       "  33641,\n",
       "  17233,\n",
       "  42408,\n",
       "  240460,\n",
       "  255988,\n",
       "  33270],\n",
       " 'target_mask': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"dataset-tanakh-rashi-labse-tokenized.jsonl\", \"r\") as f:\n",
    "    loaded_data = []\n",
    "    for i, doc in enumerate(f):\n",
    "        if i == 50000: break\n",
    "        loaded_data.append(json.loads(doc))\n",
    "\n",
    "loaded_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a22e210a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.extend(loaded_data)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "575e51ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query_tokenized': [332915, 118, 939, 44358, 156681, 939, 15600, 117040, 317370, 15769, 33552, 939, 246039, 45130, 320554, 15769, 119], 'target_tokenized': [22810, 14985, 26160, 15121, 14985, 189386, 22426, 14986, 30479, 107, 15071, 112, 64174, 18227, 289016, 14978, 107, 14986, 21985, 153767, 15121, 112, 14985, 63730, 15053, 22954, 15096, 170, 289016, 14978, 117, 14999, 15384, 61448, 15096, 170, 112, 289016, 14978, 112, 119, 119, 119, 17192, 360536, 15015, 170, 33408, 117, 16125, 15751, 39267, 15015, 14985, 79498, 127414, 14981, 17054, 46941, 117, 14999, 16290, 15179, 424526, 16068, 15179, 62528, 15294, 15595, 14986, 14985, 16122, 117, 15751, 99061, 117, 25549, 15751, 33608, 180756, 15438, 15165, 112, 16013, 29992, 15294, 14985, 71158, 14997, 14985, 463551, 17697, 15235, 119, 19895, 15036, 499562, 310378, 21881, 117, 18557, 15017, 16728, 166656, 92806, 15000, 15050, 142296, 117, 16728, 166656, 92806, 15000, 15050, 28701, 123899, 15000, 15899, 117, 18426, 15006, 24064, 166656, 138820, 16934, 28332, 63797, 16872, 117, 15140, 15357, 16266, 28332, 63797, 16872, 132, 15936, 15357, 15151, 18205, 117, 18557, 15036, 499562, 310378, 21881, 117, 16266, 18426, 294947, 117, 18557, 15017, 221666, 318069, 15050, 189166, 221666, 318069, 15050, 15151, 126519, 16472, 51537, 15245, 44369, 15180, 312986, 119, 35747, 16728, 166656, 92806, 15000, 15899, 131, 15357, 15151, 15429, 26199, 15588, 15429, 20743, 16728, 166656, 92806, 15000, 136, 15329, 461735, 45349, 21584, 60786, 131, 130541, 378495, 37364, 230367, 15084, 252236, 104744, 14978, 117, 46451, 15670, 24378, 15369, 15863, 15670, 65793, 460136, 14988, 117, 18557, 16266, 15826, 15032, 245584, 24935, 119, 133670, 23809, 117, 16266, 16681, 15151, 16465, 15670, 24378, 460136, 332915, 118, 939, 44358, 14988, 303821, 119, 155, 119, 28317, 14983, 487059, 28513, 171, 119, 155, 119, 274699, 15012, 487059, 14988, 23809, 117, 16266, 16681, 15151, 16465, 15670, 24378, 176977, 460136, 14988, 303821, 119], 'target_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query_tokenized': [35379,\n",
       "  916,\n",
       "  211327,\n",
       "  20259,\n",
       "  937,\n",
       "  163588,\n",
       "  31520,\n",
       "  15600,\n",
       "  136204,\n",
       "  15578,\n",
       "  302010,\n",
       "  926,\n",
       "  108654,\n",
       "  365776,\n",
       "  55514,\n",
       "  379816,\n",
       "  108654,\n",
       "  35379,\n",
       "  931,\n",
       "  15600,\n",
       "  55514,\n",
       "  74624,\n",
       "  408773,\n",
       "  20557,\n",
       "  55514,\n",
       "  165316,\n",
       "  143486,\n",
       "  136204,\n",
       "  15578,\n",
       "  302010,\n",
       "  74624,\n",
       "  408773,\n",
       "  35379,\n",
       "  931,\n",
       "  15600,\n",
       "  55514,\n",
       "  926,\n",
       "  108654],\n",
       " 'target_tokenized': [20557,\n",
       "  35930,\n",
       "  939,\n",
       "  375957,\n",
       "  918,\n",
       "  391272,\n",
       "  15578,\n",
       "  930,\n",
       "  28621,\n",
       "  236697,\n",
       "  15001,\n",
       "  41469,\n",
       "  17417,\n",
       "  133670,\n",
       "  2769,\n",
       "  268011,\n",
       "  16446,\n",
       "  408112,\n",
       "  30946,\n",
       "  22738,\n",
       "  131,\n",
       "  15088,\n",
       "  39205,\n",
       "  14997,\n",
       "  133670,\n",
       "  24096,\n",
       "  15011,\n",
       "  32250,\n",
       "  14981,\n",
       "  170,\n",
       "  407621,\n",
       "  21065,\n",
       "  29455,\n",
       "  15222,\n",
       "  15001,\n",
       "  471073,\n",
       "  235947,\n",
       "  61436,\n",
       "  15058,\n",
       "  29455,\n",
       "  117,\n",
       "  14999,\n",
       "  14985,\n",
       "  39205,\n",
       "  14997,\n",
       "  14985,\n",
       "  133670,\n",
       "  20557,\n",
       "  55514,\n",
       "  165316,\n",
       "  143486,\n",
       "  136204,\n",
       "  15578,\n",
       "  302010,\n",
       "  74624,\n",
       "  14978,\n",
       "  14981,\n",
       "  99555,\n",
       "  119,\n",
       "  919,\n",
       "  172742,\n",
       "  39699,\n",
       "  31520,\n",
       "  915,\n",
       "  117040,\n",
       "  134304,\n",
       "  33331,\n",
       "  210256,\n",
       "  59478,\n",
       "  18430,\n",
       "  74492,\n",
       "  45130,\n",
       "  130189,\n",
       "  15600,\n",
       "  33331,\n",
       "  925,\n",
       "  267897,\n",
       "  15578,\n",
       "  500340,\n",
       "  19459,\n",
       "  154025,\n",
       "  74492,\n",
       "  70255,\n",
       "  33331,\n",
       "  925,\n",
       "  267897,\n",
       "  15578,\n",
       "  926,\n",
       "  85778,\n",
       "  73843,\n",
       "  23603,\n",
       "  102066,\n",
       "  117,\n",
       "  112793,\n",
       "  20259,\n",
       "  73433,\n",
       "  15769,\n",
       "  55514,\n",
       "  917,\n",
       "  136751,\n",
       "  30374,\n",
       "  241658,\n",
       "  15600,\n",
       "  206230,\n",
       "  34644,\n",
       "  119,\n",
       "  486660,\n",
       "  15050,\n",
       "  102133,\n",
       "  14989,\n",
       "  131,\n",
       "  26733,\n",
       "  22390,\n",
       "  15246,\n",
       "  165775,\n",
       "  117,\n",
       "  18557,\n",
       "  15151,\n",
       "  15455,\n",
       "  90188,\n",
       "  29572,\n",
       "  500474,\n",
       "  350346,\n",
       "  227506,\n",
       "  15011,\n",
       "  15899,\n",
       "  119,\n",
       "  33271,\n",
       "  15127,\n",
       "  116002,\n",
       "  307387,\n",
       "  14988,\n",
       "  27971,\n",
       "  14999,\n",
       "  14985,\n",
       "  16068,\n",
       "  71598,\n",
       "  17445,\n",
       "  117,\n",
       "  19155,\n",
       "  14997,\n",
       "  16207,\n",
       "  15179,\n",
       "  15384,\n",
       "  16460,\n",
       "  89775,\n",
       "  117,\n",
       "  109811,\n",
       "  15131,\n",
       "  53909,\n",
       "  14986,\n",
       "  14981,\n",
       "  411805,\n",
       "  42752,\n",
       "  15131,\n",
       "  53909,\n",
       "  14986,\n",
       "  170,\n",
       "  252331,\n",
       "  119,\n",
       "  133670,\n",
       "  53160,\n",
       "  27262,\n",
       "  22738,\n",
       "  131,\n",
       "  15088,\n",
       "  16460,\n",
       "  15131,\n",
       "  53909,\n",
       "  14986,\n",
       "  14981,\n",
       "  411805,\n",
       "  14999,\n",
       "  14985,\n",
       "  21147,\n",
       "  15014,\n",
       "  26205,\n",
       "  68733,\n",
       "  133670,\n",
       "  170908,\n",
       "  15014,\n",
       "  15932,\n",
       "  15404,\n",
       "  14985,\n",
       "  107080,\n",
       "  14997,\n",
       "  133670,\n",
       "  2769,\n",
       "  35140,\n",
       "  15352,\n",
       "  119,\n",
       "  18953,\n",
       "  15320,\n",
       "  25795,\n",
       "  14986,\n",
       "  30479,\n",
       "  14985,\n",
       "  59978,\n",
       "  34918,\n",
       "  117,\n",
       "  14985,\n",
       "  27381,\n",
       "  50927,\n",
       "  119,\n",
       "  133670,\n",
       "  17116,\n",
       "  131,\n",
       "  15872,\n",
       "  16290,\n",
       "  117,\n",
       "  89203,\n",
       "  90804,\n",
       "  15058,\n",
       "  117,\n",
       "  16282,\n",
       "  30428,\n",
       "  91613,\n",
       "  317210,\n",
       "  79916,\n",
       "  18585,\n",
       "  28842,\n",
       "  14999,\n",
       "  47384,\n",
       "  16143,\n",
       "  14985,\n",
       "  39027,\n",
       "  2976,\n",
       "  133670,\n",
       "  15206,\n",
       "  419315,\n",
       "  15514,\n",
       "  15294,\n",
       "  20677,\n",
       "  324377,\n",
       "  14983,\n",
       "  16446,\n",
       "  65171,\n",
       "  22255,\n",
       "  117,\n",
       "  133670,\n",
       "  2769,\n",
       "  35140,\n",
       "  15352,\n",
       "  15206,\n",
       "  419315,\n",
       "  15514,\n",
       "  15294,\n",
       "  53160,\n",
       "  15275,\n",
       "  117,\n",
       "  16929,\n",
       "  2976,\n",
       "  188,\n",
       "  57865,\n",
       "  119],\n",
       " 'target_mask': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "random.shuffle(dataset)\n",
    "dataset[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a6fb4",
   "metadata": {},
   "source": [
    "And i saved dataset into jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fa81b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset-yeshibish-labse.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for sample in dataset:\n",
    "        f.write(json.dumps(sample, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea6710",
   "metadata": {},
   "source": [
    "The data set composed of tokenized sents because if after training the model we want to save it in onnx format for fast cold relise on server, so we don't need to import torch and transformers, which takes a lot of time, and not to keep it warm so it takes memory on server, we need to keep tokenizer outside the model, since we can save it in json file and load in python with tokenizers.Tokenizer in milliseconds, the same with onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0650bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER.backend_tokenizer.save(\"xlm-roberta-tokenizer.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
